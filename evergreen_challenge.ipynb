{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as s \n",
    "import re\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from scipy.stats import chi2_contingency \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"train.csv\")\n",
    "testdata = pd.read_csv(\"test.csv\")\n",
    "data_copy = traindata.copy()\n",
    "print(traindata.shape)\n",
    "traindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3796\n",
       "0    3599\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata['label'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: the data does not have a class imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                             0\n",
       "frameTagRatio                     0\n",
       "alchemy_category                  0\n",
       "alchemy_category_score            0\n",
       "avglinksize                       0\n",
       "commonlinkratio_1                 0\n",
       "commonlinkratio_2                 0\n",
       "commonlinkratio_3                 0\n",
       "commonlinkratio_4                 0\n",
       "compression_ratio                 0\n",
       "embed_ratio                       0\n",
       "framebased                        0\n",
       "hasDomainLink                     0\n",
       "spelling_errors_ratio             0\n",
       "html_ratio                        0\n",
       "image_ratio                       0\n",
       "is_news                           0\n",
       "lengthyLinkDomain                 0\n",
       "linkwordscore                     0\n",
       "news_front_page                   0\n",
       "non_markup_alphanum_characters    0\n",
       "numberOfLinks                     0\n",
       "numwords_in_url                   0\n",
       "parametrizedLinkRatio             0\n",
       "boilerplate                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "\n",
    "traindata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose features: boilerplate and label\n",
    "\n",
    "traindata = traindata.iloc[:,[2,26]]\n",
    "testdata = testdata.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords, punctuations and numbers\n",
    "\n",
    "def clean_data(data):\n",
    "    stopwords = s.words('english')\n",
    "    for i in range (data.shape[0]):\n",
    "        words_to_remove = ['''\"title\"''','''\"body\"''','''\"url\"''']\n",
    "        for w in words_to_remove:\n",
    "            data['boilerplate'].loc[i] = (data['boilerplate'].loc[i]).replace(w, \"\")\n",
    "        data['boilerplate'].loc[i] = re.sub(r'[^\\w\\s]',\"\", data['boilerplate'].loc[i])\n",
    "        word_tokens = word_tokenize (data['boilerplate'].loc[i])\n",
    "        data['boilerplate'].loc[i]=\" \".join(filter(lambda x: x not in stopwords , word_tokens))\n",
    "        data['boilerplate'].loc[i]= re.sub('\\d',\"\", data['boilerplate'].loc[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = clean_data (traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gunisha Chaturvedi\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "testdata = clean_data (testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.to_csv('C:/Users/Gunisha Chaturvedi/Dropbox/My PC (LAPTOP-1CT80JS5)/Documents/internships/traindata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('C:/Users/Gunisha Chaturvedi/Dropbox/My PC (LAPTOP-1CT80JS5)/Documents/internships/traindata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3171, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlation of alchemy_category with label using chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=list(traindata['alchemy_category'])\n",
    "l.count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alchemy_category</th>\n",
       "      <th>?</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>business</th>\n",
       "      <th>computer_internet</th>\n",
       "      <th>culture_politics</th>\n",
       "      <th>gaming</th>\n",
       "      <th>health</th>\n",
       "      <th>law_crime</th>\n",
       "      <th>recreation</th>\n",
       "      <th>religion</th>\n",
       "      <th>science_technology</th>\n",
       "      <th>sports</th>\n",
       "      <th>unknown</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1166</td>\n",
       "      <td>591</td>\n",
       "      <td>254</td>\n",
       "      <td>223</td>\n",
       "      <td>186</td>\n",
       "      <td>48</td>\n",
       "      <td>216</td>\n",
       "      <td>18</td>\n",
       "      <td>388</td>\n",
       "      <td>42</td>\n",
       "      <td>157</td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1176</td>\n",
       "      <td>350</td>\n",
       "      <td>626</td>\n",
       "      <td>73</td>\n",
       "      <td>157</td>\n",
       "      <td>28</td>\n",
       "      <td>290</td>\n",
       "      <td>13</td>\n",
       "      <td>841</td>\n",
       "      <td>30</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "alchemy_category     ?  arts_entertainment  business  computer_internet  \\\n",
       "label                                                                     \n",
       "0                 1166                 591       254                223   \n",
       "1                 1176                 350       626                 73   \n",
       "\n",
       "alchemy_category  culture_politics  gaming  health  law_crime  recreation  \\\n",
       "label                                                                       \n",
       "0                              186      48     216         18         388   \n",
       "1                              157      28     290         13         841   \n",
       "\n",
       "alchemy_category  religion  science_technology  sports  unknown  weather  \n",
       "label                                                                     \n",
       "0                       42                 157     302        4        4  \n",
       "1                       30                 132      78        2        0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data['label'],data['alchemy_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 3.857352828735912e-124\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# h0 = no relationship bw variables\n",
    "\n",
    "cont_table = [[591,254,223,186,48,216,18,388,42,157,302,4,4], [350,626,73,157,28,290,13,841,30,132,78,2,0]] \n",
    "stat, p, dof, expected = chi2_contingency(cont_table) \n",
    "  \n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p)) \n",
    "if p <= alpha: \n",
    "    print('Dependent (reject H0)') \n",
    "else: \n",
    "    print('Independent (H0 holds true)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: length of boiler plate code varies a lot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1956.3871534820826"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average length of boilerplate text from training data\n",
    "\n",
    "length=[]\n",
    "for i in range (0, traindata.shape[0]):\n",
    "    length.append(len(traindata['boilerplate'].loc[i]))\n",
    "\n",
    "sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1956, 1000)        20000000  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 80)                345920    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 20,346,001\n",
      "Trainable params: 20,346,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "58/58 [==============================] - 2103s 36s/step - loss: 0.5422 - accuracy: 0.7352\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 2296s 40s/step - loss: 0.3188 - accuracy: 0.8707\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 2171s 37s/step - loss: 0.2077 - accuracy: 0.9265\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 2066s 36s/step - loss: 0.1103 - accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 2163s 37s/step - loss: 0.0679 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x266655ab320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, ytrain = traindata['boilerplate'], traindata['label']\n",
    "\n",
    "xtest = testdata['boilerplate']\n",
    "\n",
    "vocab_size, embed_size, max_length = 20000, 1000, 1956\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "encoded_docs_train = [one_hot(d,vocab_size) for d in xtrain]\n",
    "\n",
    "encoded_docs_test = [one_hot(d,vocab_size) for d in xtest]\n",
    "\n",
    "xtrain = tf.keras.preprocessing.sequence.pad_sequences(encoded_docs_train, maxlen= max_length)\n",
    "\n",
    "xtest = tf.keras.preprocessing.sequence.pad_sequences(encoded_docs_test, maxlen= max_length)\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, embed_size, input_length= max_length))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM (units=80, activation='tanh'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yresult = model.predict_classes(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
